#%%
import json
import pandas as pd
from kiwipiepy import Kiwi
from konlpy.tag import Kkma
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer
import os

# í´ë” ë° í˜•íƒœì†Œ ì„¤ì •
input_folder = r"C:\Users\mysjh\Documents\corpus\kore_final\original_files_to_analyze\NIKL_DIALOGUE_60s\NIKL_DIALOGUE_60s"
output_folder = r"C:\Users\mysjh\Documents\corpus\results\TF_MORPHEMES_KIWI\60ëŒ€_í˜•íƒœì†Œ_ë²¡í„°"
use_tfidf = True
target_pos = {
    "ì¡°ì‚¬", "ì–´ë¯¸",             # ë¬¸ë²•ì  ìš”ì†Œ
    "ì¼ë°˜ëª…ì‚¬",                # ì˜ë¯¸ ìˆëŠ” ëª…ì‚¬ (NNG)
    "ë³´ì¡°ìš©ì–¸", "ë³´ì¡°í˜•ìš©ì‚¬", "ë™ì‚¬", "í˜•ìš©ì‚¬",  # ìš©ì–¸
    "ê´€í˜•ì‚¬",                  # ê´€í˜•ì‚¬
    "ì¼ë°˜ë¶€ì‚¬"				     # ë¶€ì‚¬
}


# ë°œí™” ë¶ˆëŸ¬ì˜¤ê¸°
def load_utterances(json_path):
    with open(json_path, encoding="utf-8") as f:
        data = json.load(f)

    utterances = []
    for doc in data["document"]:
        speakers = {s["id"]: s["age"] for s in doc["metadata"]["speaker"]}
        for u in doc["utterance"]:
            sid = u["speaker_id"]
            age = speakers.get(sid, "ë¯¸ìƒ")
            utterances.append({
                "í™”ìID": sid,
                "ì—°ë ¹ëŒ€": age,
                "ë¬¸ì¥": u["form"]
            })
    return pd.DataFrame(utterances)

# í˜•íƒœì†Œ ë¶„ì„ ë° ìƒëŒ€ë¹ˆë„ ê³„ì‚°

kiwi = Kiwi()

def extract_morphs(text):
    if not text.strip():
        return []
    result = kiwi.analyze(text)[0][0]
    return [m[0] for m in result if m[1] in target_pos]

def build_morph_vectors(df):
    counts = {}
    for row in df.itertuples():
        morphs = extract_morphs(row.ë¬¸ì¥)
        sid = row.í™”ìID
        if sid not in counts:
            counts[sid] = Counter()
        counts[sid].update(morphs)

    rows = []
    for sid, counter in counts.items():
        total = sum(counter.values())
        vec = {f"í˜•íƒœì†Œ_{k}": v / total for k, v in counter.items()}
        vec["í™”ìID"] = sid
        rows.append(vec)
    return pd.DataFrame(rows).fillna(0)

# TF-IDF ë²¡í„° ê³„ì‚°
def build_tfidf_vectors(df):
    vectorizer = TfidfVectorizer()
    tfidf = vectorizer.fit_transform(df["ë¬¸ì¥"])
    tfidf_df = pd.DataFrame(tfidf.toarray(), columns=[f"TFIDF_{t}" for t in vectorizer.get_feature_names_out()])
    tfidf_df["í™”ìID"] = df["í™”ìID"].values
    return tfidf_df

# ë³‘í•© ë° ì €ì¥
def merge_and_save(json_path, output_csv):
    utterance_df = load_utterances(json_path)
    morph_df = build_morph_vectors(utterance_df)
    
    # ë©”íƒ€ ì •ë³´ ë³‘í•©
    meta_df = utterance_df.groupby("í™”ìID").agg({
        "ì—°ë ¹ëŒ€": "first",
        "ë¬¸ì¥": lambda x: " ".join(x)
    }).reset_index()
    
    # ëª¨ë‘ ë³‘í•©
    merged = meta_df.merge(morph_df, on="í™”ìID", how="left")

    if use_tfidf:
        tfidf_df = build_tfidf_vectors(utterance_df)
        merged = merged.merge(tfidf_df, on="í™”ìID", how="left")

	#ì €ì¥
    os.makedirs(os.path.dirname(output_csv), exist_ok=True)
    merged.to_csv(output_csv, index=False, encoding="utf-8-sig")
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_csv}")

# í´ë” ë‚´ ë°˜ë³µ
def process_all_json(input_folder, output_folder):
    os.makedirs(output_folder, exist_ok=True)
    for filename in os.listdir(input_folder):
        if filename.endswith(".json"):
            print(f"ğŸ” ì²˜ë¦¬ ì¤‘: {filename}")
            json_path = os.path.join(input_folder, filename)
            output_csv = os.path.join(output_folder, filename.replace(".json", "_í˜•íƒœì†Œë²¡í„°.csv"))
            merge_and_save(json_path, output_csv)

# ì‹¤í–‰
process_all_json(input_folder, output_folder)
